---
title: "Embedding external functions in GGIR"
author: "Vincent van Hees"
date: "December 5 2019"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
urlcolor: blue


vignette: >
  %\VignetteIndexEntry{Embedding external functions in GGIR}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

```{r setup, include=FALSE}
library(reticulate)
knitr::opts_chunk$set(
  echo = TRUE,
  python.reticulate = FALSE
)
```

# Introduction

Algorithms (e.g. machine learning models) are typically developed for a specific data format and do not include the necessary data cleaning steps for real life 'out of the lab' experiments with multiple days of data per participant. As a result, it is not easy to pilot, let alone fully implement, a new algorithm on those datasets. Additional code will have to be written to read, clean, and aggregate the data in an efficient way.

GGIR now allows you to apply your algorithm written in R or Python to raw accelerometer data, while taking care of all the other processing steps. 

Internally GGIR loads the raw accelerometer data in memory blocks of about 24 hours. When the data is in memory and corrected for calibration error GGIR applies its own default algorithms, but now also the algorithm you provide via an external function file that you will have to write. The function is expected to take as input: A three-column matrix with the acceleration data, and an optional parameters argument. As output it is expected to produce a single time series.

# Example with external R function

In this example we will apply the function counts() from R package activityCounts to the raw data, which produces an estimate of Actigraph counts per second.

## Write external function

Create file **calculateCounts.R** and insert the following code:

```{R,eval=FALSE}
calculateCounts = function(data=c(), parameters=c()) {
  # data: 3 column matrix with acc data
  # parameters: the sample rate of data
  library("activityCounts")
  mycounts = counts(data=data, hertz=parameters, 
                    x_axis=1, y_axis=2, z_axis=3,
                    start_time = Sys.time())
  mycounts = mycounts[,2:4] #Note: do not provide timestamps to GGIR
  return(mycounts)
}
```

## Provide external function to GGIR

Create a new .R file for running the GGIR analysis, e.g. named `myscript.R`, and insert the following code.
Do not forget to update the filepath on the first line to point to your `calculateCounts.R` file.

```{R,eval=FALSE}
source("~/calculateCounts.R")
myfun =  list(FUN=calculateCounts,
              parameters= 30,
              expected_sample_rate= 30,
              expected_unit="g",
              colnames = c("countsX","countsY","countsZ"),
              outputres = 1,
              minlength = 1,
              outputtype="numeric",
              aggfunction = sum)
```

The above code creates object `myfun` of type `list` which is expected to come with the following elements:

- `FUN` A character string specifying the location of the external function you want to apply.
- `parameters` The parameters used by the function, which can be stored in any format (vector, matrix, list, data.frame). The user should make sure that the external function can handle this object.
- `expected_sample_rate` Expected sample rate, if the inputdata has a difference sample rate, then the data will be resampled.
- `expected_unit` Expected unit of the acceleration by external function: "mg", "g" or "ms2". If input data is different it will be converted.
- `colnames` Character vector with the names of the columns produced by the external function.
- `outputres` The resolution (seconds) of the output produced by the external function. Note, that this needs to be equal to or a multitude of the short epoch size of the g.part1 output (5 seconds) or the short epoch size should be a multitude of this resolution. In this way GGIR can aggregate or repeat the external function output to be used inside GGIR.
- `minlength` The minimum length (seconds) of input data needed, typically the window per which output is provided.
- `outputtype` Type of external function output. Set to "numeric" if data is stored in numbers (any numeric format).
- `aggfunction` If the data needs to be aggregated to match the short epoch size of the g.part1 output (5 seconds) then this element specifies what
function should be used for the aggregation, e.g. mean, sum, median.

Next, add a call to GGIR function g.shell.GGIR with `myfun` provided as one of its arguments:

```{R,eval=FALSE}
library(GGIR)
g.shell.GGIR(datadir="~/myaccelerometerdata",
             outputdir="~/myresults",
             mode=1:2,
             epochvalues2csv = TRUE,
             do.report=2,
             myfun=myfun)
```

Please see the [\underline{general GGIR vignette}](https://cran.r-project.org/package=GGIR/vignettes/GGIR.html) for more information about function g.shell.GGIR.

# Example with external Python function

In this example we will use an external Python code to estimate the dominant signal frequency per acceleration axis. Needless to say that this can also be done within R, but it only as an example of how to embed Python code.

## Write external function

Create **dominant_frequency.py** and insert the code shown below:

```{python}
import numpy

def dominant_frequency(x, sf):
  # x: vector with data values
  # sf: sample frequency
  fourier = numpy.fft.fft(x)
  frequencies = numpy.fft.fftfreq(len(x), 1/sf)
  magnitudes = abs(fourier[numpy.where(frequencies > 0)])
  peak_frequency = frequencies[numpy.argmax(magnitudes)]
  return peak_frequency
```

Create **dominant_frequency.R** that calls the python function and insert the following code:

```{R,eval=FALSE}
dominant_frequency = function(data=c(), parameters=c()) {
  # data: 3 column matrix with acc data
  # parameters: the sample rate of data
  source_python("dominant_frequency.py")
  sf=parameters
  N = nrow(data)
  ws = 5 # windowsize
  data = data.frame(t= floor(seq(0,(N-1)/sf,by=1/sf)/ws),
                    x=data[,1], y=data[,2], z=data[,3])
  df = aggregate(data, by = list(data$t), 
                 FUN=function(x) {return(dominant_frequency(x,sf))})
  df = df[,-c(1:2)]
  return(df)
}
}
```

## Provide external function to GGIR

Create a new .R file for running the GGIR analysis, e.g. named myscript.R, and insert the following blocks of code.

Specification of Python environment to use, this can also be a conda environment or docker container (see documentation R package [\underline{reticulate}](https://rstudio.github.io/reticulate/) for further details). Make sure that that this Python environment has all the required dependencies for the external function, here we will only need `numpy`.

```{R,eval=FALSE}
  library("reticulate")
  use_virtualenv("~/myvenv", required = TRUE) # Local Python environment

```

Specify a `myfun` object as explained in the R example. Do not forget to update the filepath to the `"~/dominant_frequency.R"` file.

```{R,eval=FALSE}
source("~/dominant_frequency.R")
myfun =  list(FUN=dominant_frequency,
              parameters= 30,
              expected_sample_rate= 30,
              expected_unit="g",
              colnames = c("domfreqX", "domfreqY", "domfreqZ"),
              minlength = 5,
              outputres = 5,
              outputtype="numeric",
              aggfunction = median)
```

Add a call to GGIR function g.shell.GGIR where `myfun` is provided as argument.

```{R,eval=FALSE}
library(GGIR)
g.shell.GGIR(datadir="~/myaccelerometerdata",
             outputdir="~/myresults",
             mode=1:2,
             epochvalues2csv = TRUE,
             do.report=2,
             myfun=myfun)
```


# Integration in GGIR output

## Part 1
The external function output is included in the time series produced by function GGIR function g.part1 and stored in an RData-file in `/output_nameofstudy/meta/basic`.
The resolution of these output in GGIR is set by g.shell.GGIR argument `windowsizes`, which is `c(5,900,3600)` by default. Here, the first element `5` specifies the short epoch size in seconds.
If the output of the external function is less then this resolution it will be aggregated with the function as specificied by aggfunction in the `myfun` object. In the count example we used the sum for this and for the dominant frequency example we used the median.

## Part 2
Next, in part2 GGIR aims to detect non-wear periods and imputes those. The impute time series can be found in the part 2 milestone data in folder: `/output_nameofstudy/meta/ms2.out`. If you want these to be directly stored in a csv file then set argument `epochvalues2csv = TRUE`.